{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82fefd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.transform import ProjectiveTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780f5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keypoints_and_descriptors(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def match_keypoints(des1, des2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "def find_homography(kp1, kp2, matches):\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    homography, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return homography\n",
    "\n",
    "def warp_image(image, homography, output_size):\n",
    "    warped_image = cv2.warpPerspective(image, homography, output_size)\n",
    "    return warped_image\n",
    "\n",
    "def blend_images(image1, image2):\n",
    "    blended_image = cv2.addWeighted(image1, 0.5, image2, 0.5, 0)\n",
    "    return blended_image\n",
    "\n",
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"No se pudo cargar la imagen en {path}.\")\n",
    "        else:\n",
    "            images.append(img)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7a0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar imágenes\n",
    "image_paths = ['pictures/S1.jpg', 'pictures/S2.jpg', 'pictures/S3.jpg', 'pictures/S4.jpg', 'pictures/S5.jpg']  # Ruta de las imágenes\n",
    "images = load_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142e2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(images) < 2:\n",
    "    print(\"Se necesitan al menos dos imágenes para crear una panorámica.\")\n",
    "else:\n",
    "    # Encontrar homografías entre imágenes consecutivas\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    homographies = []\n",
    "\n",
    "    for i in range(len(images) - 1):\n",
    "        keypoints1, descriptors1 = find_keypoints_and_descriptors(images[i])\n",
    "        keypoints2, descriptors2 = find_keypoints_and_descriptors(images[i + 1])\n",
    "        if keypoints1 is None or keypoints2 is None or descriptors1 is None or descriptors2 is None:\n",
    "            print(f\"No se pudieron encontrar puntos clave y descriptores para las imágenes {i} y {i + 1}.\")\n",
    "        else:\n",
    "            matches = match_keypoints(descriptors1, descriptors2)\n",
    "            if len(matches) < 4:\n",
    "                print(f\"No se encontraron suficientes coincidencias entre las imágenes {i} y {i + 1}.\")\n",
    "            else:\n",
    "                homography = find_homography(keypoints1, keypoints2, matches)\n",
    "                if homography is None:\n",
    "                    print(f\"No se pudo calcular la homografía entre las imágenes {i} y {i + 1}.\")\n",
    "                else:\n",
    "                    homographies.append(homography)\n",
    "                    keypoints.append(keypoints1)\n",
    "                    descriptors.append(descriptors1)\n",
    "\n",
    "    if len(homographies) < len(images) - 1:\n",
    "        print(\"No se pudo encontrar la homografía para todas las imágenes consecutivas.\")\n",
    "    else:\n",
    "        # Aplicar warping para alinear todas las imágenes\n",
    "        output_size = (images[0].shape[1], images[0].shape[0])\n",
    "        warped_images = [images[0]]\n",
    "        for i in range(1, len(images)):\n",
    "            warped_image = warp_image(images[i], np.linalg.inv(homographies[i - 1]), output_size)\n",
    "            warped_images.append(warped_image)\n",
    "\n",
    "        # Mezclar imágenes alineadas\n",
    "        blended_image = warped_images[0]\n",
    "        for i in range(1, len(warped_images)):\n",
    "            blended_image = blend_images(blended_image, warped_images[i])\n",
    "\n",
    "        # Mostrar la imagen panorámica resultante\n",
    "        cv2.imshow('Panoramic Image', blended_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7a0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15428cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
